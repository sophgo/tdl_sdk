# é€šç”¨yolov8éƒ¨ç½²

é¦–å…ˆè·å–yolov8å®˜æ–¹ä»“åº“ä»£ç [ultralytics/ultralytics: NEW - YOLOv8 ğŸš€ in PyTorch > ONNX > OpenVINO > CoreML > TFLite (github.com)](https://github.com/ultralytics/ultralytics)

```shell
git clone https://github.com/ultralytics/ultralytics.git
```

å†ä¸‹è½½å¯¹åº”çš„yolov8æ¨¡å‹æ–‡ä»¶ï¼Œä»¥[yolov8n](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt)ä¸ºä¾‹ï¼Œç„¶åå°†ä¸‹è½½çš„yolov8n.ptæ”¾åœ¨`ultralytics/weights/`ç›®å½•ä¸‹ï¼Œå¦‚ä¸‹å‘½ä»¤è¡Œæ‰€ç¤º

```
cd ultralytics & mkdir weights
cd weights
wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt
```

## onnxæ¨¡å‹å¯¼å‡º

è°ƒæ•´yolov8è¾“å‡ºåˆ†æ”¯ï¼Œå»æ‰`forward`å‡½æ•°çš„è§£ç éƒ¨åˆ†ï¼Œå¹¶å°†ä¸‰ä¸ªä¸åŒçš„feature mapçš„boxä»¥åŠclsåˆ†å¼€ï¼Œå¾—åˆ°6ä¸ªåˆ†æ”¯

å…·ä½“çš„å¯ä»¥åœ¨`ultralytics/`ç›®å½•ä¸‹æ–°å»ºä¸€ä¸ªæ–‡ä»¶ï¼Œå¹¶è´´ä¸Šä¸‹åˆ—ä»£ç 

```python
from ultralytics import YOLO
import types

input_size = (640, 640)

def forward2(self, x):
    x_reg = [self.cv2[i](x[i]) for i in range(self.nl)]
    x_cls = [self.cv3[i](x[i]) for i in range(self.nl)]
    return x_reg + x_cls


model_path = "./weights/yolov8s.pt"
model = YOLO(model_path)
model.model.model[-1].forward = types.MethodType(forward2, model.model.model[-1])
model.export(format='onnx', opset=11, imgsz=input_size)
```

è¿è¡Œä¸Šè¿°ä»£ç ä¹‹åï¼Œå¯ä»¥åœ¨`./weights/`ç›®å½•ä¸‹å¾—åˆ°`yolov8n.onnx`æ–‡ä»¶ï¼Œä¹‹åå°±æ˜¯å°†`onnx`æ¨¡å‹è½¬æ¢ä¸ºcvimodelæ¨¡å‹

## cvimodelå¯¼å‡º

cvimodelè½¬æ¢æ“ä½œå¯ä»¥å‚è€ƒ[appendix02-yolov5_model_deploy_helper](./appendix02-yolov5_model_deploy_helper.md)

## yolov8æ¥å£è°ƒç”¨

é¦–å…ˆåˆ›å»ºä¸€ä¸ª`cviai_handle`ï¼Œç„¶åæ‰“å¼€å¯¹åº”çš„`cvimodel`ï¼Œåœ¨è¿è¡Œæ¨ç†æ¥å£ä¹‹å‰ï¼Œå¯ä»¥è®¾ç½®è‡ªå·±æ¨¡å‹çš„ä¸¤ä¸ªé˜ˆå€¼

* `CVI_AI_SetModelThreshold` è®¾ç½®confé˜ˆå€¼
* `CVI_AI_SetModelNmsThreshold` è®¾ç½®nmsé˜ˆå€¼

æœ€ç»ˆæ¨ç†çš„ç»“æœé€šè¿‡è§£æ`cvai_object_t.info`è·å–

```c++
// create handle
cviai_handle_t ai_handle = NULL;
ret = CVI_AI_CreateHandle(&ai_handle);
  if (ret != CVI_SUCCESS) {
    printf("Create ai handle failed with %#x!\n", ret);
    return ret;
  }

// read image
VIDEO_FRAME_INFO_S bg;
ret = CVI_AI_ReadImage(strf1.c_str(), &bg, PIXEL_FORMAT_RGB_888_PLANAR);

// open model and set conf & nms threshold
ret = CVI_AI_OpenModel(ai_handle, CVI_AI_SUPPORTED_MODEL_YOLOV8_DETECTION, path_to_model);
CVI_AI_SetModelThreshold(ai_handle, CVI_AI_SUPPORTED_MODEL_YOLOV8_DETECTION, 0.5);
CVI_AI_SetModelNmsThreshold(ai_handle, CVI_AI_SUPPORTED_MODEL_YOLOV8_DETECTION, 0.5);
if (ret != CVI_SUCCESS) {
	printf("open model failed with %#x!\n", ret);
    return ret;
}

// start infer
cvai_object_t obj_meta = {0};
CVI_AI_YOLOV8_Detection(ai_handle, &bg, &obj_meta);

// analysis result
std::stringstream ss;
ss << "boxes=[";
for (uint32_t i = 0; i < obj_meta.size; i++) {
ss << "[" << obj_meta.info[i].bbox.x1 << "," << obj_meta.info[i].bbox.y1 << ","
   << obj_meta.info[i].bbox.x2 << "," << obj_meta.info[i].bbox.y2 << ","
   << obj_meta.info[i].classes << "," << obj_meta.info[i].bbox.score << "],";
}
```

## æµ‹è¯•ç»“æœ

è½¬æ¢æµ‹è¯•äº†å®˜ç½‘çš„yolov8nä»¥åŠyolov8sæ¨¡å‹ï¼Œåœ¨COCO2017æ•°æ®é›†ä¸Šè¿›è¡Œäº†æµ‹è¯•ï¼Œæµ‹è¯•å¹³å°ä¸º**cv1811h_wevb_0007a_spinor**ï¼Œå…¶ä¸­é˜ˆå€¼è®¾ç½®ä¸ºï¼š

* conf: 0.001
* nms_thresh: 0.6

![image-20230802143817141](./assets/image-20230802143817141.png)
